{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8159d4-2cbe-4846-bffa-3735d940553d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 0: Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541b8dd1-4e5d-4307-a8b0-0ff19f78cb2f",
   "metadata": {},
   "source": [
    "# Image Processing and Captioning Pipeline with AWS Services\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Welcome to this comprehensive notebook on Image Processing and Captioning Pipeline with AWS Services. This notebook demonstrates a sophisticated approach to handling, processing, and analyzing images using cutting-edge cloud technologies and artificial intelligence.\n",
    "\n",
    "\n",
    "In today's digital ecosystem, image captioning represents far more than a simple description of visual content—it stands as a crucial bridge between visual and textual information, fundamentally transforming how we interact with and derive value from digital imagery. At its core, image captioning serves as an essential accessibility tool, enabling visually impaired users to comprehend visual content through screen readers and assistive technologies. However, its significance extends well beyond accessibility, playing a pivotal role in for our use case of customizing a video generation model.\n",
    "\n",
    "The implementation of advanced image captioning, particularly through sophisticated AI models like Amazon Nova Pro, addresses several critical challenges in modern digital content management. By generating detailed, contextually aware descriptions, these systems enable powerful semantic search capabilities, allowing users to locate specific images based on natural language queries rather than relying solely on manually tagged metadata. This capability has profound implications for large-scale digital asset management, where manual captioning would be both time-prohibitive and cost-ineffective.\n",
    "\n",
    "\n",
    "In today's digital landscape, the ability to efficiently process and analyze large volumes of images has become increasingly crucial. This notebook leverages several powerful AWS services, including:\n",
    "\n",
    "* **Amazon Bedrock** with Amazon Nova Pro for intelligent image analysis\n",
    "* **Amazon S3** for scalable storage\n",
    "* **Amazon SageMaker** for notebook hosting\n",
    "\n",
    "Our pipeline implements a *multi-stage approach* that transforms raw images into searchable, analyzable assets while maintaining high performance and scalability.\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "* **Automated Processing Pipeline**:\n",
    "  * Bulk image processing\n",
    "  * Intelligent resizing and optimization\n",
    "  * Base64 encoding for API compatibility\n",
    "  * S3 storage of images\n",
    "\n",
    "* **AI-Powered Analysis**:\n",
    "  * Advanced image description generation\n",
    "  * Content-based image understanding\n",
    "  * Multi-modal AI integration\n",
    "\n",
    "* **Robust Data Management**:\n",
    "  * Efficient storage organization\n",
    "  * Metadata extraction and indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7e4d82-c9c1-4c20-b57c-059e25ecdaf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Table of Contents\n",
    "1. [Setup and Dependencies](#Setup-and-Dependencies)\n",
    "2. [Configuration and Initialization](#Configuration-and-Initialization)\n",
    "3. [Directory Management](#Directory-Management)\n",
    "4. [Display and Upload Images](#Display-and-Upload-Images)\n",
    "5. [Image Processing and Encoding](#Image-Processing-and-Encoding)\n",
    "5. [Image Description Generation](#Image-Description-Generation)\n",
    "6. [Results Visualization](#Results-Visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213cbb9f-c8c2-4104-ac4d-414635ecb5f6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61ab869-3413-496f-9e55-57a4fe2e4e30",
   "metadata": {},
   "source": [
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "!pip install -r requirements.txt"
   ],
   "id": "32a7c07e6d98f751",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9d31d68f-58a4-4a7a-98f7-e67d6e063f0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "from typing import List, Tuple, Optional\n",
    "import json\n",
    "import boto3\n",
    "import os\n",
    "import base64\n",
    "import shutil\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from IPython.display import display, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "imoprt random\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sagemaker_role_arn = get_execution_role()\n",
    "REGION = sagemaker_session.boto_region_name\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", REGION)\n",
    "%store REGION"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5f8fee8b-1d62-42db-a712-aa5cd2373d24",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Make sure all dependencies are installed before proceeding. You may need to restart your kernel if an error occurs. This notebook requires AWS credentials with appropriate permissions if not running on a SageMaker notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Enable Amazon Bedrock Models"
   ],
   "id": "2f1f9aafa031d088"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "  * Go to the [Amazon Bedrock model access page](https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/modelaccess)\n",
    "  * Select \"Modify model access\" or \"Enable Specific Models\"\n",
    "\n",
    "  ![Model Access](assets/model_access.png)\n",
    "  * Under Amazon select \"Nova Reel\" and \"Nova Pro\"\n",
    "\n",
    "  ![Select Nova Reel](assets/select_nova_reel.png)\n",
    "  * Select \"Next\" and then \"Submit\""
   ],
   "id": "bfd030d77d81c78f"
  },
  {
   "cell_type": "markdown",
   "id": "e16f4988-0ac8-498a-b59e-92cc14882009",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb5772e-fe25-4ae2-b734-00222b2d79b9",
   "metadata": {},
   "source": [
    "## Configuration and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7662ed-93b6-4343-accb-31170251c77a",
   "metadata": {},
   "source": [
    "What this section does:\n",
    "1. Retrieves configuration from AWS Systems Manager\n",
    "2. Sets up essential variables for the pipeline\n",
    "3. Validates all required parameters are present\n",
    "\n",
    "Important Variables:\n",
    "- stack_name: Your CloudFormation stack name\n",
    "- COLLECTION_ID: Identifier for image collection\n",
    "- BUCKET: S3 bucket for storing images\n",
    "- REGION: AWS region for operations\n",
    "\n",
    "The `stack_name` is the same name defined when stack is deployed in cloudformation. Fill the below variable if a different value was used during deployment. To validate the value, go to cloudformation in the console"
   ]
  },
  {
   "cell_type": "code",
   "id": "ead77754-4235-4371-beff-77803a1580ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "stack_name: str = os.environ['STACK_NAME']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "22b2f367-874b-4e0f-b8db-95c6f6b69627",
   "metadata": {},
   "source": [
    "Cloudformation stored the notebook variabes in the Systems Manager - Parameter Store. The below function pulls in these parameters into our notebook."
   ]
  },
  {
   "cell_type": "code",
   "id": "44fd97e4-9813-4f0d-8aa3-fddac366ced2",
   "metadata": {
    "tags": []
   },
   "source": [
    "def get_ssm_parameter(parameter_name: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Retrieve a parameter from AWS Systems Manager Parameter Store.\n",
    "\n",
    "    Args:\n",
    "        parameter_name (str): Name of the parameter to retrieve\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: Parameter value if found, None otherwise\n",
    "\n",
    "    Raises:\n",
    "        Exception: If parameter retrieval fails\n",
    "    \"\"\"\n",
    "    ssm = boto3.client('ssm')\n",
    "    try:\n",
    "        response = ssm.get_parameter(Name=parameter_name)\n",
    "        return response['Parameter']['Value']\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving SSM parameter {parameter_name}: {str(e)}\")\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "30a47240-df9e-4634-9612-ccc915295b15",
   "metadata": {},
   "source": [
    "Retrieve variables from ssm parameters into notebook."
   ]
  },
  {
   "cell_type": "code",
   "id": "81f849c5-0676-4be7-ae0d-60494fcc26ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "COLLECTION_ID = get_ssm_parameter(f\"/{stack_name}/collection-name\")\n",
    "INDEX_NAME = get_ssm_parameter(f\"/{stack_name}/index-name\")\n",
    "COLLECTION_ENDPOINT = get_ssm_parameter(f\"/{stack_name}/collection-endpoint\").replace('https://', '')\n",
    "BUCKET = get_ssm_parameter(f\"/{stack_name}/s3-bucket\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f9caedb9-6042-49a9-98eb-b34a425be50f",
   "metadata": {},
   "source": [
    "Store the variables that are to be shared across notebooks"
   ]
  },
  {
   "cell_type": "code",
   "id": "6de2e468-d3d5-40de-bb6b-f9b4f4bc8ed7",
   "metadata": {
    "tags": []
   },
   "source": [
    "%store COLLECTION_ID INDEX_NAME COLLECTION_ENDPOINT BUCKET"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "222bc4b2-92c8-4a88-9def-147713e7d3f9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> The <code>%store</code> Ipython magic command enables the sharing of variables across notebooks. All the stored variables will be used in latter notebooks.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12871bf5-3d38-4394-bd8d-1b5893f98416",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e963380-1d89-437c-926e-cf4179fffa16",
   "metadata": {},
   "source": [
    "## Directory Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e65ef57-eb03-4304-8906-c8962147470b",
   "metadata": {},
   "source": [
    "The organization of our image processing pipeline's directory structure represents a critical foundation for efficient data management and scalable operations. This carefully designed hierarchy creates a logical separation of concerns, enabling streamlined workflows while maintaining data integrity throughout the processing lifecycle. Each directory serves a specific purpose in the pipeline, from initial image ingestion through processing to final output generation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d394bf-e08a-415b-9816-ca78e35803b6",
   "metadata": {},
   "source": [
    "#### Target Directory Structure:\n",
    "```plaintext\n",
    ".\n",
    "├── 📁 base64_images/              \n",
    "│   └── [Encoded image files]\n",
    "├── 📁 image_download/             \n",
    "│   └── [Temporary processing files]\n",
    "├── 📁 images/                      \n",
    "│   └── [Training and source images]\n",
    "├── 📁 output_video/              \n",
    "│   └── [Generated media content]\n",
    "└── 📁 src/                        \n",
    "    └── [Core processing scripts]\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b6b16743-d125-44fe-bb8a-d00b27187b41",
   "metadata": {
    "tags": []
   },
   "source": [
    "IMAGES_DIR: str = \"images\"\n",
    "BASE64_IMAGES_DIR: str = \"base64_images\"\n",
    "IMAGE_DOWNLOAD_DIR: str = \"image_download\"\n",
    "CODE_DIR: str = \"src\"\n",
    "OUTPUT_DIR: str = \"output_video\"\n",
    "\n",
    "VECTOR_STORE_NAME_PREFIX: str = \"titan-mm-image-collection\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1b6e8c9a-40bf-4066-9379-20a606784a62",
   "metadata": {},
   "source": [
    "Store variables for use in other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "id": "3c0154f3-e702-4197-b0fe-9c5013f2e460",
   "metadata": {
    "tags": []
   },
   "source": [
    "%store IMAGES_DIR BASE64_IMAGES_DIR IMAGE_DOWNLOAD_DIR CODE_DIR OUTPUT_DIR VECTOR_STORE_NAME_PREFIX"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "817e1ccd-a0c1-4f87-96fb-376744703805",
   "metadata": {},
   "source": [
    "Directory initialization"
   ]
  },
  {
   "cell_type": "code",
   "id": "3a7c7a0f-fc79-4ad6-b975-1fc76d17b109",
   "metadata": {
    "tags": []
   },
   "source": [
    "def initialize_directories() -> None:\n",
    "    \"\"\"\n",
    "    Creates fresh directories for the project by removing existing ones and creating new ones.\n",
    "    \"\"\"\n",
    "    directories = [BASE64_IMAGES_DIR, IMAGE_DOWNLOAD_DIR, CODE_DIR]\n",
    "    for directory in directories:\n",
    "        shutil.rmtree(directory, ignore_errors=True)\n",
    "        os.makedirs(directory, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4e1e4a2a-1b77-42ab-aabd-ba621a965534",
   "metadata": {
    "tags": []
   },
   "source": [
    "initialize_directories()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bea5b1f5-a005-4ec2-ab8c-4a2944dfc396",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note:</b> All existing directories will be cleaned and recreated whenever `initialize_directories` function is executed.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17120b39-dfe9-4fb4-9526-fa2d06fa27e1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74913058-b5b7-4edf-a767-67ab9a2f88bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Display and Upload Images\n",
    "In this section, we will examine a subset of the available images and upload them to S3."
   ]
  },
  {
   "cell_type": "code",
   "id": "259f9f93-fa8e-410f-af47-eaf1b4dc1db9",
   "metadata": {
    "tags": []
   },
   "source": [
    "def load_image_paths() -> List[str]:\n",
    "    \"\"\"\n",
    "    Loads all JPG images from the images directory.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Sorted list of image file paths\n",
    "    \"\"\"\n",
    "    image_paths = sorted([\n",
    "        os.path.join(IMAGES_DIR, f)\n",
    "        for f in os.listdir(IMAGES_DIR)\n",
    "        if f.endswith(\".jpg\")\n",
    "    ])\n",
    "    return image_paths"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7d000ee1-f5bd-4cd1-96c9-3a02ad73b6e2",
   "metadata": {},
   "source": [
    "image_paths = load_image_paths()\n",
    "%store image_paths"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "332a806e-e865-4526-974c-f332d5b68189",
   "metadata": {},
   "source": [
    "Paths of the images"
   ]
  },
  {
   "cell_type": "code",
   "id": "a42fd68e-20c2-46b8-849f-a7c1d5ef047c",
   "metadata": {
    "tags": []
   },
   "source": [
    "print(image_paths)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0bd118d2-c847-4a2d-bedd-edbdcaec4360",
   "metadata": {},
   "source": [
    "Display images in a grid"
   ]
  },
  {
   "cell_type": "code",
   "id": "e777e89f-0a57-4180-819f-c3188fafc662",
   "metadata": {
    "tags": []
   },
   "source": [
    "def show_image_grid(\n",
    "    image_paths: List[str],\n",
    "    rows: int,\n",
    "    cols: int,\n",
    "    figsize: Tuple[int, int] = (15, 15)\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Displays a grid of images using matplotlib.\n",
    "\n",
    "    Args:\n",
    "        image_paths (List[str]): List of image file paths\n",
    "        rows (int): Number of rows in the grid\n",
    "        cols (int): Number of columns in the grid\n",
    "        figsize (Tuple[int, int]): Figure size in inches\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for idx, path in enumerate(image_paths):\n",
    "        if idx < len(axes):\n",
    "            img = plt.imread(path)\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].axis('off')\n",
    "\n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(image_paths), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bcf92307-a0df-41ea-b7b1-194af02282d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "show_image_grid(image_paths, rows=3, cols=3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "adf83ab3-efdb-4c59-a213-dacd2f3b42b9",
   "metadata": {},
   "source": [
    "Upload images to S3 bucket for processing"
   ]
  },
  {
   "cell_type": "code",
   "id": "22f74982-c25f-49da-b735-ac4a4f36054a",
   "metadata": {
    "tags": []
   },
   "source": [
    "!aws s3 sync $IMAGES_DIR s3://$BUCKET/$IMAGES_DIR/ "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "93059459-afba-4ce1-ab6d-8925900b767b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0acf27-4427-4581-9483-b4f216189633",
   "metadata": {},
   "source": [
    "## Image Processing and Encoding\n",
    "This section transforms your original images into a format suitable for AI processing:\n",
    "\n",
    "1. Image Resizing:\n",
    "   - Converts all images to 1280x720 resolution\n",
    "   - Maintains aspect ratio\n",
    "   - Optimizes for processing speed and quality\n",
    "\n",
    "2. Base64 Encoding:\n",
    "   - Converts images to text format for API compatibility\n",
    "   - Preserves image data without quality loss\n",
    "   - Prepares images for Amazon Nova Pro model input\n",
    "\n",
    "**Processing parameters:**\n",
    "- Target Resolution: 1280x720 pixels\n",
    "- Output Format: PNG (before encoding)\n",
    "- Encoding: Base64 UTF-8\n",
    "\n",
    "**Step-by-step Process:**\n",
    "1. Load original image\n",
    "2. Resize to target resolution\n",
    "3. Convert to PNG format\n",
    "4. Encode to Base64\n",
    "5. Save encoded result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5424029-0aba-4599-9dba-ab1dbc2b3c32",
   "metadata": {
    "tags": []
   },
   "source": [
    "Resize images to a standard resolution (1280x720) and encode64 encode them"
   ]
  },
  {
   "cell_type": "code",
   "id": "885defd1-cced-4637-8a7f-1aa96c89430f",
   "metadata": {
    "tags": []
   },
   "source": [
    "def resize_and_encode(\n",
    "    image_path: str,\n",
    "    output_size: Tuple[int, int] = (1280, 720)\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Resizes an image and converts it to Base64 format.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the source image\n",
    "        output_size (Tuple[int, int]): Desired output dimensions (width, height)\n",
    "\n",
    "    Returns:\n",
    "        str: Base64 encoded string of the processed image\n",
    "\n",
    "    Raises:\n",
    "        PIL.UnidentifiedImageError: If the image file cannot be opened\n",
    "        IOError: If there are issues reading the file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img_resized = img.resize(output_size, Image.LANCZOS)\n",
    "            buffered = BytesIO()\n",
    "            img_resized.save(buffered, format=\"PNG\")\n",
    "            img_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "        return img_base64\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "        raise"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8a2ad984-da9d-4867-b797-c6108a5cca61",
   "metadata": {},
   "source": [
    "Apply `resize_and_encode` function to all images."
   ]
  },
  {
   "cell_type": "code",
   "id": "760da235-57b0-486e-8357-bfd5deb27236",
   "metadata": {
    "tags": []
   },
   "source": [
    "resized_base64s: List[str] = [\n",
    "    resize_and_encode(image_path)\n",
    "    for image_path in tqdm(image_paths)\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6f7b6925-1112-49b1-bfba-49751a11c971",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Note:</b> Converting all images to Base64 format. This may take a minute depending on the number and size of images.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1544e927-e1cc-4226-8801-32f543c7d455",
   "metadata": {},
   "source": [
    "Function to save base64 encoded images."
   ]
  },
  {
   "cell_type": "code",
   "id": "e0c30e45-0e80-49fc-908f-957ff780902a",
   "metadata": {
    "tags": []
   },
   "source": [
    "def save_base64_string(base64_string: str, output_file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves a Base64 encoded string to a file.\n",
    "    \n",
    "    Args:\n",
    "        base64_string (str): The Base64 encoded string to save\n",
    "        output_file_path (str): Destination file path\n",
    "    \"\"\"\n",
    "    with open(output_file_path, \"w\") as file:\n",
    "        file.write(base64_string)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f3bfeb0e-8798-4f22-8792-a4a8b4e2f426",
   "metadata": {},
   "source": [
    "Save processed images."
   ]
  },
  {
   "cell_type": "code",
   "id": "297914bd-f185-4faf-899e-34b4796ac365",
   "metadata": {
    "tags": []
   },
   "source": [
    "for base64_img, img_path in zip(resized_base64s, image_paths):\n",
    "    output_path = os.path.join(\n",
    "        BASE64_IMAGES_DIR,\n",
    "        os.path.basename(img_path).replace(\".jpg\", \".txt\")\n",
    "    )\n",
    "    save_base64_string(base64_img, output_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1803e6c5-0fcd-4dcc-80f0-226d2dfa615c",
   "metadata": {},
   "source": [
    "Upload resized and encoded images to S3"
   ]
  },
  {
   "cell_type": "code",
   "id": "37cc4306-cf6d-4c3c-a990-7da148a4885c",
   "metadata": {
    "tags": []
   },
   "source": [
    "!aws s3 sync $BASE64_IMAGES_DIR s3://$BUCKET/$BASE64_IMAGES_DIR/"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8dcf0a3c-72c1-48da-a943-e27eda323457",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7699ad04-7297-4cae-af23-794195420e1f",
   "metadata": {},
   "source": [
    "## Image Description Generation\n",
    "\n",
    "**What this section does:**\n",
    "\n",
    "Uses Amazon Nova Pro AI model to generate detailed descriptions of each image.\n",
    "\n",
    "**Process explanation:**\n",
    "1. Takes Base64 encoded image as input\n",
    "2. Sends to Amazon Nova Pro through AWS Bedrock\n",
    "3. Receives and processes AI-generated description\n",
    "4. Stores results for each image\n",
    "\n",
    "Using AWS Bedrock with Amazon Nova Pro model to generate detailed descriptions of each image. We will be inputting the base64 image together with the prompt `Generate a detailed description of the image.` to generate a caption for the image."
   ]
  },
  {
   "cell_type": "code",
   "id": "65e46f28-d100-41b2-b7de-ace54c5ff1f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "def get_image_description(base64_image: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a description of an image using AWS Bedrock's Amazon Nova Pro model.\n",
    "\n",
    "    Args:\n",
    "        base64_image (str): Base64 encoded image\n",
    "\n",
    "    Returns:\n",
    "        str: Generated description of the image\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If the API response structure is unexpected\n",
    "        Exception: For other API-related errors\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"image\": {\n",
    "                            \"format\": \"png\",\n",
    "                            \"source\": {\n",
    "                                  \"bytes\": base64_image\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Generate a detailed description of the image.\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    # Configure the inference parameters.\n",
    "    inf_params = {\"maxTokens\": 300, \"topP\": 0.1, \"topK\": 20, \"temperature\": 0.3}\n",
    "\n",
    "    try:\n",
    "        native_request = {\n",
    "            \"schemaVersion\": \"messages-v1\",\n",
    "            \"messages\": messages,\n",
    "            \"inferenceConfig\": inf_params,\n",
    "        }\n",
    "        # Invoke the model and extract the response body.\n",
    "        response = bedrock_client.invoke_model(modelId=\"us.amazon.nova-pro-v1:0\", body=json.dumps(native_request))\n",
    "        model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "        return model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating description: {str(e)}\")\n",
    "        raise"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7a3954b9-c4e9-4823-b33c-dc47f2963c9a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Processing:</b> Generating descriptions for all images. This process may take a couple minutes depending on the number of images as each image needs to be processed by the model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ca4c7-8ca3-40ef-82d8-755536e1264f",
   "metadata": {},
   "source": [
    "Loop through all images and store it in a list."
   ]
  },
  {
   "cell_type": "code",
   "id": "b3ffef02-df3b-415a-a523-16fb9e3e191b",
   "metadata": {
    "tags": []
   },
   "source": [
    "image_descriptions: List[str] = []\n",
    "for base64_img in tqdm(resized_base64s):\n",
    "    description = get_image_description(base64_img)\n",
    "    image_descriptions.append(description)\n",
    "    time.sleep(10 + random.uniform(0, 5))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4e66c922-f0e7-45b1-9e5a-b42ff3b16ff3",
   "metadata": {},
   "source": [
    "Store the images to be shared across notebooks."
   ]
  },
  {
   "cell_type": "code",
   "id": "20547482-2cec-42ac-acf7-16ec26dc06fd",
   "metadata": {},
   "source": [
    "%store image_descriptions"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1a00f520-c9e1-4423-a5c6-c55c3e035a9b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec614a4-e7c4-4bc8-8806-182b5f12544c",
   "metadata": {},
   "source": [
    "## Results Visualization\n",
    "What this section does:\n",
    "Displays processed images alongside their AI-generated descriptions for review and validation.\n",
    "\n",
    "**Visualization details:**\n",
    "1. Shows original images at specified width (default: 500px)\n",
    "2. Displays AI-generated description below each image\n",
    "3. Limits display to specified number of images (default: 5) to prevent notebook overload"
   ]
  },
  {
   "cell_type": "code",
   "id": "e926758c",
   "metadata": {
    "tags": []
   },
   "source": [
    "def display_results(\n",
    "    paths: List[str],\n",
    "    descriptions: List[str],\n",
    "    num_images: int = 5,\n",
    "    image_width: int = 500\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Creates a markdown display of images and their descriptions.\n",
    "\n",
    "    Args:\n",
    "        paths (List[str]): List of image paths\n",
    "        descriptions (List[str]): List of image descriptions\n",
    "        num_images (int): Number of images to display\n",
    "        image_width (int): Width of displayed images in pixels\n",
    "    \"\"\"\n",
    "    markdown_content = \"\"\n",
    "    for path, desc in zip(paths[:num_images], descriptions[:num_images]):\n",
    "        desc = desc.replace('\\n', '')\n",
    "        markdown_content += f\"\"\"\n",
    "| <img src=\"{path}\" width=\"{image_width}\"/> |\n",
    "|:----------------:|\n",
    "| {desc} |\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "    display(Markdown(markdown_content))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eaa84a50",
   "metadata": {},
   "source": [
    "display_results(image_paths, image_descriptions)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "da479ee6-c170-4815-9ece-accb65bbc20c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>🎉 Congratulations!</b> You have successfully completed the image processing notebook!\n",
    "\n",
    "Key accomplishments:\n",
    "- ✅ Processed and resized all images\n",
    "- ✅ Generated Base64 encodings\n",
    "- ✅ Stored data in S3\n",
    "- ✅ Generated image descriptions using Amazon Nova Pro\n",
    "- ✅ Created visualization of results\n",
    "\n",
    "You can now proceed to the next notebook in the series.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "id": "debbb11d-e781-45c2-a4b5-cd99131ed901",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
