{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71115aba-73d4-43ed-97be-3cedbe8ee84c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 4: Putting everything together\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Throughout our previous explorations, we've delved into a comprehensive process that encompasses several key steps in working with text/image data and Generative AI driven content generation. We began by examining how to describe images using a multi-modal approach, which allows us to capture both visual and textual information about an image. We then progressed to ingesting these images, along with their associated metadata, into OpenSearch, a powerful and flexible search and analytics engine. This step enables us to create a searchable database of visual content. Building upon this foundation, we explored querying the database effectively, allowing us to retrieve relevant images based on specific criteria or descriptions. Finally, we ventured into the realm of video generation, learning how to create dynamic visual content based on textual prompts with and without an accompanying image.\n",
    "\n",
    "In this culminating notebook, we will synthesize all of these components into a streamlined, end-to-end process. By leveraging the code, resources, and insights we've accumulated throughout our journey, we'll construct a unified system that seamlessly integrates each step. The ultimate goal of this notebook is to empower you with the ability to input a single prompt and, in response, receive a generated video that not only aligns with your prompt but also incorporates relevant imagery sourced from our OpenSearch database. This holistic approach represents the convergence of various cutting-edge technologies, including natural language processing, image analysis, database management, and AI-driven video generation. By the conclusion of this notebook, you'll have a powerful tool at your disposal, capable of transforming simple text inputs into rich, visually compelling video content, all while leveraging a vast repository of pre-existing visual data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306df6f4a80cda4e",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Dependencies](#Setup-and-Dependencies)\n",
    "2. [Configuration and Initialization](#Configuration-and-Initialization)\n",
    "3. [Define Prompts](#Define-Prompts)\n",
    "4. [Helper Function](#Helper-Function)\n",
    "5. [VRAG Function](#VRAG-Function)\n",
    "6. [Loading and Formatting Prompts](#Loading-and-Formatting-Prompts)\n",
    "7. [Processing Multiple Videos](#Processing-Multiple-Videos)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be32cffbfd0b06d",
   "metadata": {},
   "source": [
    "## Setup and Dependencies\n",
    "\n",
    "First, we'll import the necessary libraries and modules. We'll also import functions from our previous notebooks to avoid code duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c21efba-4e96-4a13-9504-30308b450a1f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/02/25 20:42:23] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/02/25 20:42:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=556917;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=936870;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import nbimporter\n",
    "import boto3\n",
    "import os\n",
    "from _00_image_processing import resize_and_encode \n",
    "from _01_oss_ingestion import query_open_search, get_oss_client\n",
    "from _02_video_gen_text_only import download_and_display_video, start_video_generation, monitor_video_generation\n",
    "from _03_video_gen_text_image import build_model_input\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca0f9df62e5cc31",
   "metadata": {},
   "source": [
    "## Configuration and Initialization\n",
    "\n",
    "Next, we'll retrieve our stored variables from previous notebooks and initialize our AWS clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23eb6ef7-5470-4a99-9b87-b22d583a3210",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/02/25 20:42:24] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/02/25 20:42:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=323406;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=651686;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%store -r REGION\n",
    "%store -r COLLECTION_ENDPOINT\n",
    "%store -r INDEX_NAME\n",
    "%store -r OUTPUT_DIR\n",
    "%store -r BUCKET\n",
    "\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\", REGION)\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e243cd8a840e",
   "metadata": {},
   "source": [
    "## Define Prompts\n",
    "\n",
    "In this crucial step of our video generation pipeline, we focus on creating two types of prompts for producing our desired videos:\n",
    "\n",
    "1. **OBJECT_PROMPT**:\n",
    "   This prompt is a description of the main subject or object that we want to feature in our video. It should be specific enough to guide the image retrieval process from our OpenSearch database.\n",
    "\n",
    "2. **ACTION_PROMPT**:\n",
    "   This prompt describes the camera movement or action we want to see in the generated video. It's essential for creating dynamic and engaging content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "274410a2-ec15-4924-b747-f9e5c1ef7836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OBJECT_PROMPT = \"red shoes\"\n",
    "ACTION_PROMPT = \"Small glowing particles drift in the background behind the shoes.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ac00927a097d07",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note:</b> Engineering a descriptive prompt can highly impact the quality of the generated video. It is recommended to experiment with different iterations of the prompt to get the best version of the video.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88405bf2-91e9-41d2-b8c4-0fb5fdd65cda",
   "metadata": {},
   "source": [
    "## Helper Function\n",
    "\n",
    "The function `read_s3_text()`:\n",
    "- Retrieves and decodes a **text file stored in S3**.\n",
    "- Handles potential errors if the file is missing or cannot be accessed.\n",
    "\n",
    "This is useful for reading **stored image metadata** before generating a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c65a5c5-e811-4f93-8f34-81f52a194a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_s3_text(bucket_name: str, file_key: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads a text file from S3 and returns its content.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): S3 bucket name.\n",
    "        file_key (str): Key (path) of the file in S3.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = s3_client.get_object(Bucket=bucket_name, Key=file_key)\n",
    "        return response['Body'].read().decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file from S3: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e63d5de-d2ca-480a-a1a2-d5ab4a7ae485",
   "metadata": {},
   "source": [
    "## V-RAG Function\n",
    "\n",
    "The `vrag` (Video Retrieval Augmented Generation) function combines multiple processes into a streamlined workflow for creating AI-generated videos. This function handles everything from finding the right image to producing the final video content.\n",
    "\n",
    "Here are the steps it follows:\n",
    "\n",
    "1. **OpenSearch Query and Image Discovery**\n",
    "   Using the provided `image_prompt`, the function searches our OpenSearch database to find the most relevant matching image.\n",
    "\n",
    "2. **Image Data Extraction and Processing**\n",
    "   Once an image is found, the function gets its S3 file path and retrieves the Base64-encoded version, preparing it for video generation.\n",
    "\n",
    "3. **Model Input Construction**\n",
    "   The function combines the retrieved image with the video prompt to create a complete package that tells the AI model what to create.\n",
    "\n",
    "4. **AWS Bedrock Video Generation**\n",
    "   Using this input package, the function starts the video generation process through AWS Bedrock's AI models.\n",
    "\n",
    "5. **Generation Monitoring and Status Tracking**\n",
    "   The function keeps track of the generation process until the video is complete, providing updates along the way.\n",
    "\n",
    "If no matching images are found in OpenSearch, the function skips video generation entirely to avoid errors. This design makes the `vrag` function both efficient and reliable, turning what would normally be several separate steps into one smooth operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa04bf82-4584-417d-8c99-c048dd782087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vrag(image_prompt: str, camera_prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves an image from OpenSearch and generates a video based on the given prompts.\n",
    "\n",
    "    Args:\n",
    "        image_prompt (str): The prompt used to search for an image in OpenSearch.\n",
    "        camera_prompt (str): The video generation prompt.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated video's S3 URI.\n",
    "    \"\"\"\n",
    "    oss_client = get_oss_client(COLLECTION_ENDPOINT, REGION)\n",
    "    results = query_open_search(\n",
    "        bedrock_runtime=bedrock_runtime, \n",
    "        oss_client=oss_client, \n",
    "        index_name=INDEX_NAME, \n",
    "        prompt=image_prompt, \n",
    "        top_k=1\n",
    "    )\n",
    "\n",
    "    if not results:\n",
    "        print(f\"Warning: No images found for '{image_prompt}', skipping video generation.\")\n",
    "        return None\n",
    "\n",
    "    # Extract the image from S3\n",
    "    file_key = \"/\".join(results[0]['_source']['image_base64_s3_uri'].split('/')[3:])\n",
    "    image_base64 = read_s3_text(BUCKET, file_key)\n",
    "\n",
    "    # Build model input for video generation\n",
    "    model_input = build_model_input(\n",
    "        camera_prompt, \n",
    "        image_base64=image_base64, \n",
    "        duration=6, \n",
    "        fps=24, \n",
    "        resolution=\"1280x720\", \n",
    "        seed=0\n",
    "    )\n",
    "\n",
    "    # Start video generation\n",
    "    invocation = start_video_generation(bedrock_runtime, BUCKET, model_input)\n",
    "    return monitor_video_generation(bedrock_runtime, invocation[\"invocationArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770ccd92-72c6-4ea0-93fd-18373cfa3a26",
   "metadata": {},
   "source": [
    "## Loading and Formatting Prompts\n",
    "\n",
    "The `load_and_format_prompts` function serves as a component in our automated video generation pipeline. This function is designed to streamline the process of creating diverse and engaging video content by dynamically formatting pre-defined prompt templates. At its core, the function begins by accessing a file named `prompts.txt`. This file contains a collection of carefully crafted prompt templates, each designed to guide the generation of a unique video scene. These templates are not static; instead, they include placeholders that allow for dynamic customization. The two primary placeholders used in our templates are `<object_prompt>` and `<action_prompt>`. These act as variables that can be filled with a wide range of objects and actions, respectively. For example, a template might read: \"Show a <object_prompt> <action_prompt> in a bustling city street.\" This template could then be transformed into numerous specific prompts by filling in different objects and actions.\n",
    "\n",
    "Once the function has read the templates from the file, it proceeds to the formatting stage. Here, it systematically replaces the placeholders with actual values. These values could be randomly selected from predefined lists, chosen based on user input, or even generated by another AI model. This replacement process breathes life into the templates, turning them into specific, varied instructions for video generation. The beauty of this approach lies in its flexibility and scalability. With a single set of templates, we can generate an almost limitless variety of prompts. This is particularly valuable in scenarios where we need to create multiple unique video scenes without repetitive manual input. After processing all the templates, the function compiles the fully formatted prompts into a list. This list becomes a valuable resource for the subsequent stages of our video generation workflow. Each prompt in the list represents a potential video scene, complete with specific objects and actions to be depicted.\n",
    "\n",
    "By automating this prompt generation and formatting process, we significantly enhance the efficiency of our video creation pipeline. It allows for rapid iteration and experimentation, enabling us to generate a wide array of video concepts quickly. This approach not only saves time but also opens up possibilities for creating more diverse and creative video content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d23a15f-358a-4a19-a4ba-fc78a7b841ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_format_prompts(file_path: str = \"prompts.txt\", object_prompt: str = \"red shoes\", action_prompt: str = \"Camera rotates counter clockwise in slow motion\"):\n",
    "    \"\"\"\n",
    "    Reads prompt templates from a file and replaces placeholders with provided object and action prompts.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the text file containing prompt templates.\n",
    "        object_prompt (str): Object to be placed in the video (e.g., 'red shoes').\n",
    "        action_prompt (str): Action to be performed (e.g., 'Camera rotates counter clockwise in slow motion').\n",
    "\n",
    "    Returns:\n",
    "        list: List of formatted video prompts.\n",
    "    \"\"\"\n",
    "    formatted_prompts = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            prompt_template = line.strip()\n",
    "            formatted_prompt = (\n",
    "                prompt_template.replace(\"<object_prompt>\", object_prompt)\n",
    "                               .replace(\"<action_prompt>\", action_prompt)\n",
    "            )\n",
    "            formatted_prompts.append(formatted_prompt)\n",
    "    return formatted_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ee48cae3adea340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load prompts from file\n",
    "formatted_prompts = load_and_format_prompts(\"prompts.txt\", OBJECT_PROMPT, ACTION_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea49ec30-f3ff-494f-8a04-45f1ffaa5ce8",
   "metadata": {},
   "source": [
    "## Processing Multiple Videos\n",
    "\n",
    "The `process_videos_from_prompts` function orchestrates the creation of multiple videos based on a list of prompts. This function streamlines the video generation pipeline, handling everything from image retrieval to final video production.\n",
    "\n",
    "Key steps in the function:\n",
    "\n",
    "1. **Prompt Iteration**\n",
    "   The function loops through each formatted prompt in the provided list, initiating a separate video generation process for each.\n",
    "\n",
    "2. **Image Search via OpenSearch**\n",
    "   For each prompt, the function queries OpenSearch using the `OBJECT_PROMPT`. This step aims to find a relevant image that matches the main subject of the video.\n",
    "\n",
    "3. **Input Payload Construction**\n",
    "   Once an appropriate image is found, the function assembles the necessary input data for video generation. This includes the formatted prompt, the retrieved image, and various video parameters.\n",
    "\n",
    "4. **Video Generation Initiation**\n",
    "   With the input payload ready, the function kicks off the video generation job through AWS Bedrock.\n",
    "\n",
    "5. **Progress Monitoring and URI Collection**\n",
    "   The function keeps track of each video's generation process, collecting the S3 URIs of the completed videos.\n",
    "\n",
    "An important feature of this function is its error handling: if OpenSearch fails to find a matching image for a particular prompt, that video generation is skipped, allowing the process to continue with the remaining prompts.\n",
    "\n",
    "The function's code demonstrates its efficiency:\n",
    "\n",
    "- It uses a single OpenSearch client for all queries, improving performance.\n",
    "- It extracts the necessary image data from S3 and builds the model input for each video.\n",
    "- It leverages helper functions like `build_model_input()`, `start_video_generation()`, and `monitor_video_generation()` to modularize the process.\n",
    "- The function returns a list of tuples, each containing the final video URI and its corresponding formatted prompt, providing a comprehensive output for further use or analysis.\n",
    "\n",
    "This function exemplifies how complex, multi-step processes can be automated and streamlined, enabling the efficient production of multiple AI-generated videos from a set of prompts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1e20d3d-8d52-47c1-be31-742eaba5f2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_videos_from_prompts(prompt_list, object_prompt):\n",
    "    \"\"\"\n",
    "    Processes multiple video generations using formatted prompts.\n",
    "\n",
    "    Args:\n",
    "        prompt_list (list): List of formatted prompts.\n",
    "        object_prompt (str): The object to search for in OpenSearch.\n",
    "\n",
    "    Returns:\n",
    "        list: List of tuples containing (video URI, formatted prompt).\n",
    "    \"\"\"\n",
    "    video_uris = []\n",
    "    oss_client = get_oss_client(COLLECTION_ENDPOINT, REGION)\n",
    "\n",
    "    for i, formatted_prompt in enumerate(prompt_list):\n",
    "        print(f\"Processing video {i+1}/{len(prompt_list)}: {formatted_prompt}\")\n",
    "\n",
    "        # Query OpenSearch for the object only (not the full sentence)\n",
    "        results = query_open_search(\n",
    "            bedrock_runtime=bedrock_runtime, \n",
    "            oss_client=oss_client, \n",
    "            index_name=INDEX_NAME, \n",
    "            prompt=object_prompt, \n",
    "            top_k=1\n",
    "        )\n",
    "\n",
    "        if not results:\n",
    "            print(f\"Warning: No images found for '{object_prompt}', skipping this prompt.\")\n",
    "            continue\n",
    "\n",
    "        # Extract image from S3\n",
    "        file_key = \"/\".join(results[0]['_source']['image_base64_s3_uri'].split('/')[3:])\n",
    "        image_base64 = read_s3_text(BUCKET, file_key)\n",
    "\n",
    "        # Build model input\n",
    "        model_input = build_model_input(\n",
    "            formatted_prompt, \n",
    "            image_base64=image_base64, \n",
    "            duration=6, \n",
    "            fps=24, \n",
    "            resolution=\"1280x720\", \n",
    "            seed=0\n",
    "        )\n",
    "\n",
    "        # Start video generation\n",
    "        invocation = start_video_generation(bedrock_runtime, BUCKET, model_input)\n",
    "        video_uri = monitor_video_generation(bedrock_runtime, invocation[\"invocationArn\"])\n",
    "        video_uris.append((video_uri, formatted_prompt))\n",
    "\n",
    "    return video_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2c2fca3-a513-4755-869f-ecd72c99251c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/02/25 21:54:29] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/02/25 21:54:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=800704;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=774380;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 1/5: A tight ground-level shot capturing red shoes surrounded by low fog, while Small glowing particles drift in the background behind the shoes..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> <span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">POST</span>                                                                       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">258</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://33seuasang99soqla4t3.us-east-1.aoss.amazonaws.com:443/vrag-index/_</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">search</span>                                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m \u001b[1;38;2;215;175;0mPOST\u001b[0m                                                                       \u001b]8;id=907232;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=767498;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://33seuasang99soqla4t3.us-east-1.aoss.amazonaws.com:443/vrag-index/_\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255msearch\u001b[0m                                                                     \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video generation job started successfully.\n",
      "Job arn:aws:bedrock:us-east-1:344659571055:async-invoke/ezhmru1lm2b1 is in progress. Started at: 2025-05-02 21:54:30+00:00\n",
      "Job arn:aws:bedrock:us-east-1:344659571055:async-invoke/ezhmru1lm2b1 is in progress. Started at: 2025-05-02 21:54:30+00:00\n",
      "Job arn:aws:bedrock:us-east-1:344659571055:async-invoke/ezhmru1lm2b1 is in progress. Started at: 2025-05-02 21:54:30+00:00\n",
      "Video generation completed. Video available at: s3://vragtest2-s3bucket-nydb69qplxtd/ezhmru1lm2b1/output.mp4\n",
      "Processing video 2/5: A moody wide shot of red shoes positioned near flowing smoke trails, while soft ambient lighting shifts slowly.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/02/25 21:57:33] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> <span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">POST</span>                                                                       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">258</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://33seuasang99soqla4t3.us-east-1.aoss.amazonaws.com:443/vrag-index/_</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">search</span>                                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/02/25 21:57:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m \u001b[1;38;2;215;175;0mPOST\u001b[0m                                                                       \u001b]8;id=509351;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=86076;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://33seuasang99soqla4t3.us-east-1.aoss.amazonaws.com:443/vrag-index/_\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255msearch\u001b[0m                                                                     \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video generation job started successfully.\n",
      "Job arn:aws:bedrock:us-east-1:344659571055:async-invoke/304i5i85egj3 is in progress. Started at: 2025-05-02 21:57:33+00:00\n",
      "Job arn:aws:bedrock:us-east-1:344659571055:async-invoke/304i5i85egj3 is in progress. Started at: 2025-05-02 21:57:33+00:00\n",
      "Job arn:aws:bedrock:us-east-1:344659571055:async-invoke/304i5i85egj3 is in progress. Started at: 2025-05-02 21:57:33+00:00\n",
      "Video generation completed. Video available at: s3://vragtest2-s3bucket-nydb69qplxtd/304i5i85egj3/output.mp4\n",
      "Processing video 3/5: A grounded cinematic shot of red shoes placed in shallow water, while gentle waves reflect moving light above.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/02/25 22:00:36] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> <span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">POST</span>                                                                       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">258</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://33seuasang99soqla4t3.us-east-1.aoss.amazonaws.com:443/vrag-index/_</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">search</span>                                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/02/25 22:00:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m \u001b[1;38;2;215;175;0mPOST\u001b[0m                                                                       \u001b]8;id=343049;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=726870;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://33seuasang99soqla4t3.us-east-1.aoss.amazonaws.com:443/vrag-index/_\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255msearch\u001b[0m                                                                     \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video generation job started successfully.\n",
      "Job arn:aws:bedrock:us-east-1:344659571055:async-invoke/6plaz8psuw96 is in progress. Started at: 2025-05-02 22:00:37+00:00\n",
      "Job arn:aws:bedrock:us-east-1:344659571055:async-invoke/6plaz8psuw96 is in progress. Started at: 2025-05-02 22:00:37+00:00\n",
      "Job arn:aws:bedrock:us-east-1:344659571055:async-invoke/6plaz8psuw96 is in progress. Started at: 2025-05-02 22:00:37+00:00\n",
      "Video generation completed. Video available at: s3://vragtest2-s3bucket-nydb69qplxtd/6plaz8psuw96/output.mp4\n",
      "Processing video 4/5: A tight front-facing composition of red shoes backlit by dancing flames in the distance, while sparks drift nearby.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/02/25 22:03:40] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> <span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">POST</span>                                                                       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">258</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://33seuasang99soqla4t3.us-east-1.aoss.amazonaws.com:443/vrag-index/_</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">search</span>                                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/02/25 22:03:40]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m \u001b[1;38;2;215;175;0mPOST\u001b[0m                                                                       \u001b]8;id=848094;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=41700;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://33seuasang99soqla4t3.us-east-1.aoss.amazonaws.com:443/vrag-index/_\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255msearch\u001b[0m                                                                     \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video generation job started successfully.\n",
      "Job arn:aws:bedrock:us-east-1:344659571055:async-invoke/acue5j47fllx is in progress. Started at: 2025-05-02 22:03:40+00:00\n",
      "Job arn:aws:bedrock:us-east-1:344659571055:async-invoke/acue5j47fllx is in progress. Started at: 2025-05-02 22:03:40+00:00\n",
      "Job arn:aws:bedrock:us-east-1:344659571055:async-invoke/acue5j47fllx is in progress. Started at: 2025-05-02 22:03:40+00:00\n",
      "Video generation completed. Video available at: s3://vragtest2-s3bucket-nydb69qplxtd/acue5j47fllx/output.mp4\n",
      "Processing video 5/5: A clean cinematic shot of red shoes placed under falling snow, while the environment stays silent and still.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/02/25 22:06:44] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> <span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">POST</span>                                                                       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">258</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://33seuasang99soqla4t3.us-east-1.aoss.amazonaws.com:443/vrag-index/_</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">search</span>                                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/02/25 22:06:44]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m \u001b[1;38;2;215;175;0mPOST\u001b[0m                                                                       \u001b]8;id=475779;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=116051;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://33seuasang99soqla4t3.us-east-1.aoss.amazonaws.com:443/vrag-index/_\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255msearch\u001b[0m                                                                     \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video generation job started successfully.\n",
      "Job arn:aws:bedrock:us-east-1:344659571055:async-invoke/0r0ennseda8p is in progress. Started at: 2025-05-02 22:06:44+00:00\n",
      "Job arn:aws:bedrock:us-east-1:344659571055:async-invoke/0r0ennseda8p is in progress. Started at: 2025-05-02 22:06:44+00:00\n",
      "Job arn:aws:bedrock:us-east-1:344659571055:async-invoke/0r0ennseda8p is in progress. Started at: 2025-05-02 22:06:44+00:00\n",
      "Video generation completed. Video available at: s3://vragtest2-s3bucket-nydb69qplxtd/0r0ennseda8p/output.mp4\n"
     ]
    }
   ],
   "source": [
    "# Generate multiple videos\n",
    "video_uris = process_videos_from_prompts(formatted_prompts, OBJECT_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc7ab19-1b23-4c0b-b6d7-e67418587d04",
   "metadata": {},
   "source": [
    "## Generating and Displaying Videos\n",
    "\n",
    "The final stage of our video generation pipeline handles the presentation of our created videos within the Jupyter notebook environment. This process ensures that users can immediately view and validate the results of their video generation requests.\n",
    "\n",
    "Key Steps in the Process:\n",
    "\n",
    "1. **Video Download Management**\n",
    "   The function iterates through each video URI in our collection, downloading the generated videos from their S3 storage locations to local paths for viewing.\n",
    "\n",
    "2. **HTML Display Construction**\n",
    "   For each successfully downloaded video, the code constructs an HTML segment that includes:\n",
    "   - A numbered heading with the video's corresponding prompt text\n",
    "   - A video player with standard playback controls\n",
    "   - Appropriate sizing (640x360) for comfortable viewing\n",
    "\n",
    "3. **Error Handling**\n",
    "   The process includes robust error management:\n",
    "   - Skips any videos that failed to generate (indicated by missing URIs)\n",
    "   - Catches and reports any download errors that might occur\n",
    "   - Continues processing remaining videos even if some fail\n",
    "\n",
    "The implementation code shows how this is achieved through careful error handling and HTML construction, ensuring a smooth viewing experience within the notebook. Each video is presented with its associated prompt, making it easy to verify that the generation matched the intended instructions.\n",
    "\n",
    "This final step completes our video generation pipeline, providing immediate visual feedback on the success of our video creation process while maintaining stability through comprehensive error handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eeaef855-7018-480e-ae33-ec2465f9b7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <h3>Video 1: A tight ground-level shot capturing red shoes surrounded by low fog, while Small glowing particles drift in the background behind the shoes..</h3>\n",
       "            <video width=\"640\" height=\"360\" controls>\n",
       "                <source src=\"output_video/video_1.mp4\" type=\"video/mp4\">\n",
       "                Your browser does not support the video tag.\n",
       "            </video>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <h3>Video 2: A moody wide shot of red shoes positioned near flowing smoke trails, while soft ambient lighting shifts slowly.</h3>\n",
       "            <video width=\"640\" height=\"360\" controls>\n",
       "                <source src=\"output_video/video_2.mp4\" type=\"video/mp4\">\n",
       "                Your browser does not support the video tag.\n",
       "            </video>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <h3>Video 3: A grounded cinematic shot of red shoes placed in shallow water, while gentle waves reflect moving light above.</h3>\n",
       "            <video width=\"640\" height=\"360\" controls>\n",
       "                <source src=\"output_video/video_3.mp4\" type=\"video/mp4\">\n",
       "                Your browser does not support the video tag.\n",
       "            </video>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <h3>Video 4: A tight front-facing composition of red shoes backlit by dancing flames in the distance, while sparks drift nearby.</h3>\n",
       "            <video width=\"640\" height=\"360\" controls>\n",
       "                <source src=\"output_video/video_4.mp4\" type=\"video/mp4\">\n",
       "                Your browser does not support the video tag.\n",
       "            </video>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <h3>Video 5: A clean cinematic shot of red shoes placed under falling snow, while the environment stays silent and still.</h3>\n",
       "            <video width=\"640\" height=\"360\" controls>\n",
       "                <source src=\"output_video/video_5.mp4\" type=\"video/mp4\">\n",
       "                Your browser does not support the video tag.\n",
       "            </video>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display all generated videos\n",
    "video_html = \"\"\n",
    "for i, (video_uri, formatted_prompt) in enumerate(video_uris):\n",
    "    if not video_uri:\n",
    "        print(f\"Skipping Video {i+1} due to missing video URI.\")\n",
    "        continue\n",
    "\n",
    "    local_video_path = os.path.join(OUTPUT_DIR, f\"video_{i+1}.mp4\")\n",
    "    \n",
    "    try:\n",
    "        s3_client.download_file(BUCKET, \"/\".join(video_uri.split('/')[3:]), local_video_path)\n",
    "\n",
    "        video_html += f\"\"\"\n",
    "        <div style=\"margin-bottom: 20px;\">\n",
    "            <h3>Video {i+1}: {formatted_prompt}</h3>\n",
    "            <video width=\"640\" height=\"360\" controls>\n",
    "                <source src=\"{local_video_path}\" type=\"video/mp4\">\n",
    "                Your browser does not support the video tag.\n",
    "            </video>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading video {i+1}: {e}\")\n",
    "\n",
    "display(HTML(video_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b275ae37ca42f496",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>🎉 Congratulations!</b> You have successfully completed the video generation pipeline notebook!\n",
    "\n",
    "Key accomplishments:\n",
    "- ✅ Combined multiple processes into a streamlined workflow\n",
    "- ✅ Defined a prompt for VRAG\n",
    "- ✅ Implemented a single function for VRAG\n",
    "- ✅ Created dynamic prompt formatting\n",
    "- ✅ Processed and displayed multiple videos\n",
    "\n",
    "You have now created a powerful tool capable of transforming simple text inputs into rich, visually compelling video content while leveraging a vast repository of pre-existing visual data.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9ac9d0e504c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
