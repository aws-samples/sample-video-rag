{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1",
   "metadata": {},
   "source": [
    "# Step 2: Video Generation with Text Only\n",
    "\n",
    "## Text-to-Video Generation with AWS Bedrock\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Welcome to this comprehensive notebook on Text-to-Video Generation using AWS Bedrock's `nova-reel` model. This notebook demonstrates how to transform textual descriptions into dynamic video content using state-of-the-art AI technology.\n",
    "\n",
    "Text-to-video generation represents a significant advancement in generative AI, enabling the creation of visual content directly from natural language descriptions. This capability opens up new possibilities for content creation, storytelling, and visual communication without requiring specialized video production skills or equipment.\n",
    "\n",
    "In this notebook, we'll explore how AWS Bedrock's `nova-reel` model can interpret textual prompts and generate corresponding video sequences that match the described scenes, actions, and visual elements. The process involves several key steps:\n",
    "\n",
    "* **Building Model Input** – Constructing the request payload for video generation\n",
    "* **Starting Video Generation** – Initiating an asynchronous job using AWS Bedrock\n",
    "* **Monitoring Job Status** – Tracking progress and waiting until completion\n",
    "* **Downloading & Displaying Video** – Retrieving the generated video from S3 and rendering it in the notebook\n",
    "\n",
    "This notebook builds upon the image processing capabilities demonstrated in the previous notebook, extending our pipeline to include video generation capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Dependencies](#Setup-and-Dependencies)\n",
    "2. [Configuration and Initialization](#Configuration-and-Initialization)\n",
    "3. [Constructing the Model Input](#1.-Constructing-the-Model-Input)\n",
    "4. [Initiating Video Generation](#2.-Initiating-Video-Generation)\n",
    "5. [Monitoring Video Generation](#3.-Monitoring-Video-Generation)\n",
    "6. [Downloading and Displaying the Video](#4.-Downloading-and-Displaying-the-Video)\n",
    "7. [Running the Complete Workflow](#Running-the-Complete-Workflow)\n",
    "8. [Results and Next Steps](#Results-and-Next-Steps)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3",
   "metadata": {},
   "source": [
    "## Setup and Dependencies\n",
    "\n",
    "First, we'll import the necessary libraries and modules for video generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4",
   "metadata": {},
   "source": [
    "## Configuration and Initialization\n",
    "\n",
    "Next, we'll retrieve our stored variables from previous notebooks and initialize our AWS clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r BUCKET\n",
    "%store -r OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client(\"bedrock-runtime\")\n",
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5",
   "metadata": {},
   "source": [
    "We'll ensure our output directory exists for storing generated videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6",
   "metadata": {},
   "source": [
    "## 1. Constructing the Model Input\n",
    "\n",
    "### Function: `build_model_input`\n",
    "\n",
    "This function builds a structured input payload for video generation.\n",
    "\n",
    "#### Key Parameters\n",
    "\n",
    "- `prompt`: The **text prompt** describing the desired scene.\n",
    "- `image_base64`: Optional **reference image** in Base64 format.\n",
    "- `duration`: The **length** of the video in seconds.\n",
    "- `fps`: **Frame rate** of the video.\n",
    "- `resolution`: **Output video resolution** (default: `1280x720`).\n",
    "- `seed`: A **random seed** for consistent generation.\n",
    "\n",
    "#### Functionality\n",
    "\n",
    "- If an **image is provided**, it's added to the payload.\n",
    "- Defines **video parameters** such as duration, FPS, and resolution.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Note:</b> The seed parameter allows for reproducible results. Using the same seed with identical inputs will produce similar video outputs, which can be useful for iterative refinement.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_input(prompt, image_base64=None, duration=6, fps=24, resolution=\"1280x720\", seed=0):\n",
    "    \"\"\"\n",
    "    Constructs the input payload for the Bedrock video generation model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Text prompt for video generation.\n",
    "        image_base64 (str): Base64 encoded image data.\n",
    "        duration (int): Duration of the video in seconds.\n",
    "        fps (int): Frames per second for the video.\n",
    "        resolution (str): Resolution of the video.\n",
    "        seed (int): Seed for deterministic generation.\n",
    "    \n",
    "    Returns:\n",
    "        dict: The formatted model input payload.\n",
    "    \"\"\"\n",
    "    output = {\n",
    "        \"taskType\": \"TEXT_VIDEO\",\n",
    "        \"textToVideoParams\": {\n",
    "            \"text\": prompt,\n",
    "            # \"images\": image_parameter\n",
    "        },\n",
    "        \"videoGenerationConfig\": {\n",
    "            \"durationSeconds\": duration,\n",
    "            \"fps\": fps,\n",
    "            \"dimension\": resolution,\n",
    "            \"seed\": seed\n",
    "        },\n",
    "    }\n",
    "    if image_base64:\n",
    "        output['textToVideoParams']['images'] = [{\"format\": \"png\", \"source\": {\"bytes\": image_base64}}]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7",
   "metadata": {},
   "source": [
    "## 2. Initiating Video Generation\n",
    "\n",
    "### Function: `start_video_generation`\n",
    "\n",
    "This function submits a **video generation job** to AWS Bedrock.\n",
    "\n",
    "#### Key Parameters\n",
    "\n",
    "- `bedrock_runtime`: AWS **Bedrock runtime client**.\n",
    "- `bucket`: The **S3 bucket** where output videos will be stored.\n",
    "- `model_input`: The formatted **JSON payload** for video generation.\n",
    "\n",
    "#### Process\n",
    "\n",
    "1. Calls `start_async_invoke()` to trigger video creation.\n",
    "2. Saves results in the **specified S3 bucket**.\n",
    "3. Returns an **invocation ARN** to track progress.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Important:</b> Video generation is an asynchronous process that may take several minutes to complete. The function returns immediately with an ARN that can be used to monitor progress.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_video_generation(bedrock_runtime, bucket, model_input):\n",
    "    \"\"\"\n",
    "    Starts a video generation job using Bedrock's Text-to-Video model.\n",
    "\n",
    "    Args:\n",
    "        bedrock_runtime: Initialized Bedrock Runtime client.\n",
    "        bucket (str): S3 bucket for storing output video.\n",
    "        prompt (str): Text prompt for video generation.\n",
    "\n",
    "    Returns:\n",
    "        dict: Invocation response from the Bedrock API.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Start the asynchronous video generation job\n",
    "        invocation = bedrock_runtime.start_async_invoke(\n",
    "            modelId=\"amazon.nova-reel-v1:0\",\n",
    "            modelInput=model_input,\n",
    "            outputDataConfig={\n",
    "                \"s3OutputDataConfig\": {\"s3Uri\": f\"s3://{bucket}\"}\n",
    "            }\n",
    "        )\n",
    "        print(\"Video generation job started successfully.\")\n",
    "        return invocation\n",
    "    except Exception as e:\n",
    "        error_message = e.response[\"Error\"][\"Message\"] if \"Error\" in e.response else str(e)\n",
    "        print(f\"Error starting video generation: {error_message}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8",
   "metadata": {},
   "source": [
    "## 3. Monitoring Video Generation\n",
    "\n",
    "### Function: `monitor_video_generation`\n",
    "\n",
    "This function continuously checks the **status** of the video generation job.\n",
    "\n",
    "#### Key Parameters\n",
    "\n",
    "- `bedrock_runtime`: AWS **Bedrock runtime client**.\n",
    "- `invocation_arn`: The **job ID** returned from `start_video_generation`.\n",
    "\n",
    "#### Process\n",
    "\n",
    "1. Polls AWS Bedrock for **job status** (`InProgress`, `Completed`, or `Failed`).\n",
    "2. If **successful**, retrieves the **S3 URI** of the video.\n",
    "3. If **failed**, logs the error and stops execution.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Note:</b> The function checks the job status every 60 seconds to avoid excessive API calls while still providing timely updates.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_video_generation(bedrock_runtime, invocation_arn):\n",
    "    \"\"\"\n",
    "    Monitors the status of the video generation job until completion.\n",
    "\n",
    "    Args:\n",
    "        bedrock_runtime: Initialized Bedrock Runtime client.\n",
    "        invocation_arn (str): ARN of the video generation invocation.\n",
    "\n",
    "    Returns:\n",
    "        str: S3 URI of the generated video.\n",
    "    \"\"\"\n",
    "    status = \"InProgress\"\n",
    "    while status not in [\"Completed\", \"Failed\"]:\n",
    "        response = bedrock_runtime.get_async_invoke(invocationArn=invocation_arn)\n",
    "        status = response[\"status\"]\n",
    "\n",
    "        if status == \"Completed\":\n",
    "            s3_uri = response[\"outputDataConfig\"][\"s3OutputDataConfig\"][\"s3Uri\"]\n",
    "            print(f\"Video generation completed. Video available at: {s3_uri}/output.mp4\")\n",
    "            return f\"{s3_uri}/output.mp4\"\n",
    "        elif status == \"InProgress\":\n",
    "            print(f\"Job {invocation_arn} is in progress. Started at: {response['submitTime']}\")\n",
    "        elif status == \"Failed\":\n",
    "            print(f\"Job {invocation_arn} failed. Reason: {response['failureMessage']}\")\n",
    "            raise RuntimeError(\"Video generation failed.\")\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9",
   "metadata": {},
   "source": [
    "## 4. Downloading and Displaying the Video\n",
    "\n",
    "### Function: `download_and_display_video`\n",
    "\n",
    "This function fetches the **generated video from S3** and plays it in the notebook.\n",
    "\n",
    "#### Key Parameters\n",
    "\n",
    "- `s3_client`: AWS **S3 client** for file operations.\n",
    "- `bucket`: The **S3 bucket** storing the video.\n",
    "- `video_uri`: The **S3 path** to the generated video.\n",
    "- `output_dir`: **Local directory** for saving the video.\n",
    "\n",
    "#### Process\n",
    "\n",
    "1. Extracts the **video filename** from the S3 URI.\n",
    "2. Downloads the video **from S3 to local storage**.\n",
    "3. Uses **IPython's `Video` widget** to display it inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_display_video(s3_client, bucket, video_uri, output_dir):\n",
    "    \"\"\"\n",
    "    Downloads the generated video from S3 and displays it in the notebook.\n",
    "\n",
    "    Args:\n",
    "        s3_client: Initialized S3 client.\n",
    "        bucket (str): S3 bucket containing the video.\n",
    "        video_uri (str): URI of the video in S3.\n",
    "\n",
    "    Returns:\n",
    "        Video: IPython Video object for display.\n",
    "    \"\"\"\n",
    "    local_path = f\"{output_dir}/{video_uri.split('/')[3]}.mp4\"\n",
    "    print(local_path)\n",
    "    s3_client.download_file(bucket, \"/\".join(video_uri.split(\"/\")[3:]), local_path)\n",
    "    print(f\"Video downloaded to {local_path}.\")\n",
    "    return Video(local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10",
   "metadata": {},
   "source": [
    "## Running the Complete Workflow\n",
    "\n",
    "Now we'll put everything together to generate a video from a text prompt. First, let's define our prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"Closeup of a large seashell in the sand, gentle waves flow around the shell. Camera zoom in.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11",
   "metadata": {},
   "source": [
    "Next, we'll build the model input payload using our prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model input payload\n",
    "model_input = build_model_input(PROMPT)\n",
    "model_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Important:</b> The following cell will start the video generation process, which may take several minutes to complete. The notebook will poll for status updates every 60 seconds.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main workflow\n",
    "try:\n",
    "    # Step 1: Start video generation\n",
    "    invocation_response = start_video_generation(bedrock_runtime, BUCKET, model_input)\n",
    "    invocation_arn = invocation_response[\"invocationArn\"]\n",
    "\n",
    "    # Step 2: Monitor the job\n",
    "    video_s3_uri = monitor_video_generation(bedrock_runtime, invocation_arn)\n",
    "\n",
    "    # Step 3: Download and display the video\n",
    "    local_path = download_and_display_video(s3_client, BUCKET, video_s3_uri, OUTPUT_DIR)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during video generation: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13",
   "metadata": {},
   "source": [
    "If you need to display the video again, you can use the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_display_video(s3_client, BUCKET, video_s3_uri, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14",
   "metadata": {},
   "source": [
    "## Results and Next Steps\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>🎉 Congratulations!</b> You have successfully completed the text-to-video generation notebook!\n",
    "\n",
    "Key accomplishments:\n",
    "- ✅ Created a structured input payload for video generation\n",
    "- ✅ Initiated an asynchronous video generation job\n",
    "- ✅ Monitored the job status until completion\n",
    "- ✅ Downloaded and displayed the generated video\n",
    "</div>\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next notebook, we'll explore how to enhance video generation by incorporating both text prompts and reference images, which can provide more control over the visual style and content of the generated videos.\n",
    "\n",
    "Proceed to [Step 3: Video Generation with Text and Image](_03_video_gen_text_image.ipynb) to learn how to use image conditioning for video generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
